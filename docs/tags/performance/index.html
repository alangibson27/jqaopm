<html>
<head lang="en">
    <meta charset="UTF-8">
    <meta name="viewport" content="initial-scale=1">
    <meta name="description" content="ZX Spectrum Emulator with Network Play Capability">
    <meta property="og:image" content="http://plus-f.socialthingy.com/plus-f.png">
    <title>Plus-F</title>
    <link rel="stylesheet" href="/css/plusf.css">
    <link href="https://fonts.googleapis.com/css?family=Signika" rel="stylesheet" type="text/css">
</head>
<body>
<div class="header">
    <div class="content">
        <img class="logo" src="/plus-f.png"/>
        <div class="inner-logo">
          <img class="logo-noborder" src="/plus-f-title.png"/>
          <div>Spectrum over IP</div>
        </div>
    </div>
</div>
<nav class="nav">
    <ul>
        <li><a href="/">HOME</a></li>
        <li><a href="/download">DOWNLOAD</a></li>
        <li><a href="/emulator">EMULATOR</a></li>
        <li><a href="/guest">GUEST</a></li>
        <li><a href="/connect">CONNECT</a></li>
        <li><a href="/games">GAMES</a></li>
        <li><a href="/blog">VANITY PUBLISHING</a></li>
    </ul>
</nav>
<div class="content">



<h1>Going Too Quickly, Working Too Hard (13-Dec-2016)</h1>
<div><p>The just-about-holding-together addition of tape loading emulation I told you about
<a href="../if-you-only-do-one-thing">last time</a> was the last but one of the major bits
of +F. Having reached this milestone, I decided to take some time out and enjoy
playing a game or two of Match Day II before doing any more work on it. My work
may have stopped, but it turns out my computer was working as hard as ever.</p>

<p>The user experience was fairly good, at first glance, with the emulation running
without crashes and at full speed. Indeed, I&rsquo;d even had time to add a &ldquo;turbo&rdquo; mode
which would run the emulation as fast as possible, designed to remove the boredom
of waiting for tapes to load (although this does give a somewhat less authentic
experience and you should hang your head in shame if you do use it). The problem
was that when I had +F running for more than a couple of minutes, the fan on
my laptop would whoosh up to full speed, and stay there more or less until +F
stopped. A quick check with <code>top</code> confirmed that +F was using a whole core of
the laptop&rsquo;s dual-core processor.</p>

<p>By any measure, that&rsquo;s too much for a Spectrum emulator running on modern hardware.
The <a href="../standing-on-the-shoulders-of-giants">FUSE</a> emulator written in C uses only
a few percent of the available CPU capacity on the same computer and OS, and while
I wasn&rsquo;t expecting to achieve that level of performance from a Java application
(a deliberate trade-off of raw performance for fewer cross-platform difficulties),
I was still surprised it was quite so processor-hungry. But why?</p>

<p>I&rsquo;ll spare you the blow-by-blow details, except to say that a few profiling
sessions using <a href="https://github.com/RichardWarburton/honest-profiler/wiki">honest-profiler</a>
showed that the problem lay in the rendering of the display. The antiquated display
hardware of the Spectrum was efficient both in terms of memory and execution time
(while also giving us the famous <a href="http://speccyholic.tumblr.com/post/89194660510/the-spectrums-secret-weapon">attribute clash</a>)
but does make it slightly convoluted to generate a pixel-based RGB bitmap. Somewhere
in that display emulation were a few methods in particular that appeared to be hogging
the CPU unexpectedly. The surprising thing is that these methods did little else
apart from looking up various mappings between Spectrum display co-ordinates and
the corresponding window co-ordinates. Thinking ahead, I&rsquo;d decided to pre-compute
these calculations and store the results in an array, since they&rsquo;d be needed on
every single display refresh, so I couldn&rsquo;t see why these would be slow.</p>

<p>And there was my mistake.</p>

<p>I&rsquo;d assumed that array lookups are less expensive than repeated method calls, but
that wasn&rsquo;t actually the case for the calculations that I had precomputed. When
you include bounds checking and whatever else is involved in array access, it
actually turned out to be <em>more</em> expensive than recalculating the co-ordinates on
every call. In trying to outsmart the JVM with some optimisations of my own, I&rsquo;d
actually worked against it and stopped it from doing its own, more effective, optimisations
to the code.</p>

<p>For the JVM is very clever indeed. (It does this sort of thing all day, every day, so
it ought to be an expert, I suppose.) Based on the methods it sees being executed
as your program runs, it can choose to compile and inline them as it sees fit. Inlining
in particular tends to work best where methods are short, with the upshot that
<a href="https://techblug.wordpress.com/2013/08/19/java-jit-compiler-inlining/">adding method calls can make your code run faster</a>.</p>

<p>Of course, when it comes to Java code, you could argue that you&rsquo;re better to start
off with code that composes lots of calls to small methods anyway, and you&rsquo;d be
right. If nothing else, it means that your code is easier to reason about and test,
but as an added bonus you&rsquo;re also staying out of the JVM&rsquo;s way and letting it do
what it&rsquo;s best at.</p>

<p>The mistake I made is one which has been known for a long time, and which <a href="https://shreevatsa.wordpress.com/2008/05/16/premature-optimization-is-the-root-of-all-evil/">Knuth</a>
popularised with his statement <em>premature optimisation is the root of all evil</em>.
Software may have moved on in many ways since he said that in 1974, but to me the
problem of premature optimisation is more human than technological, and I&rsquo;d be surprised
if we were that much less susceptible to it now than we were then. In my case,
with no evidence to support me, I assumed that certain operations were going to
be costly, and wrote bad code based on that faulty assumption.</p>

<p>How could I have avoided this?</p>

<p>It&rsquo;s a tricky balance. On the one hand, in my original Python implementation of
+F, by doing no profiling or performance testing until the very end, <a href="../fundamentals">I ended
up wasting time on an implementation that would never have been fit for purpose</a>. Clearly, I could have done with paying a bit more attention to
performance up-front in that case. In the case of the Java version of +F, by
fixating on performance too early (probably a consequence of having been burned
a little by the fact the first attempt at +F was so slow), I ended up with an
inefficient application.</p>

<p>I think it all boils down to gathering evidence and acting upon that. Where you
have requirements that a program should exhibit a certain level of performance
(in my case not needing an entire CPU core in order to emulate a computerised beermat
from the 1980s), it&rsquo;s important to test for this, just like you would test whether
it behaves correctly or not, and to bake this testing into your development cycle
if you can.</p></div>


<h1>The Fundamentals are Important (13-Nov-2016)</h1>
<div><p>The relationship between a programmer and a language is much like the relationship between the cricketer and a
bat. Unless you know how to handle it properly, you&rsquo;re not going to achieve much and you could end up in a lot of pain.
And so it was with +F, or at least the program which eventually became +F. It started off with the working title
<em>QAOPM</em>, and was written in Python.</p>

<p>The choice of language was driven by a couple of things.</p>

<p>First, I aimed to write a cross-platform emulator. Python is readily available on both of my target platforms (Linux and
Windows), and I planned to use the Pygame library to build the user interface. Second, I love Python&rsquo;s
<a href="https://www.python.org/dev/peps/pep-0020/">principles</a>, its elegance and its clarity. (I know the fact that whitespace
is syntactically relevant bothers some people, but it looks natural to me, and it&rsquo;s never tripped me up.) My
opportunities to work with this language had been limited to a few utilities and the odd simple web application,
and I relished the chance to learn more on a project that was a bit more meaty.</p>

<p>That decision made, I set about writing +F, and four enjoyable months later (well, as enjoyable as jumping armpits-deep
into the Z80 reference manual can be) I had a basic working version which could load a program from a snapshot file,
emulate the Z80 and render the Spectrum display. It couldn&rsquo;t accept keyboard input so you couldn&rsquo;t actually do much with
it, but I was sure that would follow in short order. All the unit tests worked, the display rendering was accurate,
and it was time to fire it all up together for the first time and give it a shakedown.</p>

<p>And &hellip; it was slow.</p>

<p>Not a little sluggish, not jerky from time to time, but truly, painfully slow. Right from the outset, I&rsquo;d been sure
that a modern PC (even my 2010-vintage laptop) would be able to handle emulation of an 8-bit computer without breaking
sweat. After all, there&rsquo;s already an <a href="http://torinak.com/qaop">emulator written in JavaScript</a> that runs at full speed
in a browser, so while I was expecting I&rsquo;d need to make a few tweaks here and there, I had just assumed that the emulator
would be fast enough. Not so. What was the problem?</p>

<p>Me.</p>

<p>Not Python. Definitely not Python.</p>

<p>Me.</p>

<p><em>(At this point, I want to make perfectly clear that I&rsquo;m certain that in the hands of an experienced Python programmer,
it is possible to write an emulator with the requisite speed to be usable. If that sounds like you, I&rsquo;ve left all of
the code for the <a href="https://github.com/alangibson27/qaopm">Python +F on GitHub</a>, and in the interests of learning how to
become a better programmer, I&rsquo;d be very happy if you had the time to take a look and could explain to me how I could
have achieved a better outcome. I&rsquo;m not having a bash at Python, I&rsquo;m having a bash at me.)</em></p>

<p>I&rsquo;ve earned a living for almost two decades writing software in Java, and more recently Scala. I&rsquo;ve become to an
extent conditioned to think of software solutions in terms of interactions between objects (although obviously Scala
opens the door to a more functional approach too), and that&rsquo;s how I approached the Python predecessor of +F.</p>

<p>The processor was a class. Each Z80 operation was a class, with related operations existing in a class hierarchy. Memory was
a class. The display was a class. Almost everything was nicely organised into classes, each with short methods which
did strictly one thing - just the way you&rsquo;d unthinkingly build almost any Java application. For all
that I could read and write Python, though, I&rsquo;d neglected the fact that an interpreted, dynamically-typed language
behaves differently to a compiled, statically-typed language.</p>

<p>It turns out this was a really big problem for me because my code fell foul of a combination of Python&rsquo;s weak spots (according to
<a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips#Loops">this page</a>) - lots of field dereferencing in tight, nested for-loops.
In any other application, I may not have noticed this, but an emulator is basically just one big outer loop, which runs some
other loops inside it on each iteration. The outermost loop runs once for each display refresh cycle (50 times a second
in the case of the Spectrum), with each iteration running the processor&rsquo;s fetch-execute cycle up to about 17000 times,
followed by another loop which sets the colour of each of the 49152 pixels in the display. Lots of for-loops and, in
my implementation, lots of dereferencing of fields on collaborating objects.</p>

<p>Here&rsquo;s a representative example of how the code for a single emulated Z80 operation (<code>add a, (hl)</code>) looked, before I
realised this there were going to be speed issues:</p>

<pre><code class="language-python">class OpAddAHlIndirect(BaseOp):
    def __init__(self, processor, memory):
        BaseOp.__init__(self)
        self.processor = processor
        self.memory = memory

    def execute(self):
        value = self.memory.peek(self.processor.get_16bit_reg('hl'))
        _add_a(self.processor, value, False)

    def t_states(self):
        return 7

    def __str__(self):
        return 'add a, (hl)'

def _add_a(processor, value, carry):
    signed_a = to_signed(processor.main_registers['a'])
    if carry:
        value = (value + 1) &amp; 0xff
    result, half_carry, full_carry = bitwise_add(processor.main_registers['a'], value)
    signed_result = to_signed(result)
    processor.main_registers['a'] = result
    processor.set_condition('s', signed_result &lt; 0)
    processor.set_condition('z', result == 0)
    processor.set_condition('h', half_carry)
    processor.set_condition('p', (signed_a &lt; 0) != (signed_result &lt; 0))
    processor.set_condition('n', False)
    processor.set_condition('c', full_carry)
</code></pre>

<p>The execute method is the one that is run in the emulation loop. This single method, which could in theory be executed
up to 17000 times every 1/50th of a second, was itself doing three expensive field dereferences per iteration, and when
you include those done by the <code>_add_a</code> function it invokes, in total there are about a dozen in executing this one simple
operation!</p>

<p>Having gone back and done the background reading I ought to have done at the start, I spent a month trying to remedy the
problem, the outcome of which was that the code for our representative <code>add a, (hl)</code> operation became &hellip;</p>

<pre><code class="language-python">class OpAddAHlIndirect(BaseOp):
    def __init__(self, processor, memory):
        BaseOp.__init__(self)
        self.processor = processor
        self.memory = memory

    def execute(self, processor, memory, pc):
        value = memory[0xffff &amp; processor.get_16bit_reg('hl')]
        _add_a(processor, value, False)
        return 7, False, pc

    def __str__(self):
        return 'add a, (hl)'

def _add_a(processor, value, carry):
    signed_a = to_signed(processor.main_registers['a'])
    if carry:
        value = (value + 1) &amp; 0xff
    result, half_carry, full_carry = bitwise_add(processor.main_registers['a'], value)
    signed_result = to_signed(result)
    processor.main_registers['a'] = result
    set_condition = processor.set_condition
    set_condition('s', signed_result &lt; 0)
    set_condition('z', result == 0)
    set_condition('h', half_carry)
    set_condition('p', (signed_a &lt; 0) != (signed_result &lt; 0))
    set_condition('n', False)
    set_condition('c', full_carry)
</code></pre>

<p>&hellip; and while reducing the number of dot-dereferences (complemented with a few other recommended techniques such as
flattening nested loops) did help a bit, it wasn&rsquo;t enough to make the emulator fast enough to be viable. Suitably
discouraged, I decided to scrap the idea of writing an emulator in Python and retreated to the safer territory of Java.</p>

<p>Where had I gone wrong?</p>

<p>I had my cricket bat, I&rsquo;d carefully seasoned it with linseed oil and I&rsquo;d spent my time in the nets, honing my technique.
I&rsquo;d then tried to play snooker with it.</p>

<p>I hadn&rsquo;t understood the fundamentals of Python. You most certainly <em>can</em> write Java-esque object-oriented programs with
it, but what is cheap in Java comes with a different cost in Python. I fell into a trap
<a href="http://www.joelonsoftware.com/articles/fog0000000319.html">articulately described by Joel Spolsky</a>, where I didn&rsquo;t
see the details beneath an abstraction, and paid the price in terms of poor performance. (If you haven&rsquo;t read that
article yet, stop right now, read and understand it, read it again, then read some of the other articles on Joel on Software
before coming back here. It&rsquo;ll be well worth your while, trust me.)</p>

<p>I hope I won&rsquo;t make this particular mistake again, but how could I have avoided this problem? I could have read some
information about the performance characteristics of Python in advance of starting, of course. But given that I&rsquo;m not
especially taken with the idea of lots of up-front background reading when there&rsquo;s code I could be writing (this may or
may not be a character flaw, I leave that for you to judge), I think the best thing I could have done is reached a point
where I realised my mistake a lot sooner.</p>

<p>Premature optimisation is of course a problem in itself (more on <em>that</em> later), but a spot of up-front prototyping would have
definitely helped. For example, I could have built a representative subset of the Z80 instruction set and performance
tested a few simple routines, or built the display rendering logic and tested it standalone at the required frame rate.
I&rsquo;m sure that either of these would have made me either change the way I was writing my Python, or make the jump to
Java sooner than I did.</p>

<p>In honesty, it would have been easy to give up once I realised my best chance was to start all over again, but I did
have one thing in my favour which was going to ease the pain considerably. I&rsquo;ll tell you about that next time.</p>
</div>



</div>
</body>
</html>
